{"cells":[{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2023-07-24T09:24:35.203659Z","iopub.status.busy":"2023-07-24T09:24:35.202779Z","iopub.status.idle":"2023-07-24T09:24:45.214745Z","shell.execute_reply":"2023-07-24T09:24:45.212540Z","shell.execute_reply.started":"2023-07-24T09:24:35.203604Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Note: you may need to restart the kernel to use updated packages.\n"]},{"name":"stderr","output_type":"stream","text":["\n","[notice] A new release of pip is available: 23.2.1 -> 23.3.1\n","[notice] To update, run: python.exe -m pip install --upgrade pip\n"]}],"source":["%pip install --upgrade transformers tensorflow-gpu==2.9.0 --quiet\n","import pandas as pd\n","import numpy as np\n","import os\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n","from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n","from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n","from transformers import XLMForSequenceClassification, XLMRobertaTokenizer, XLMConfig\n","from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig\n","from transformers import TFAlbertForSequenceClassification, AlbertTokenizer, AlbertConfig\n"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2023-07-24T09:25:27.648216Z","iopub.status.busy":"2023-07-24T09:25:27.647408Z","iopub.status.idle":"2023-07-24T09:25:40.489420Z","shell.execute_reply":"2023-07-24T09:25:40.488202Z","shell.execute_reply.started":"2023-07-24T09:25:27.648180Z"},"trusted":true},"outputs":[],"source":["# load data\n","df = pd.read_csv('../Data/data.csv')  # path to multi_dataset\n","train_set = df.query(\" split=='train' \")\n","test_set = df.query(\" split=='test' \")\n","validation_set = df.query(\" split=='dev' \")\n"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2023-07-24T09:25:40.492110Z","iopub.status.busy":"2023-07-24T09:25:40.491737Z","iopub.status.idle":"2023-07-24T09:25:46.026325Z","shell.execute_reply":"2023-07-24T09:25:46.025096Z","shell.execute_reply.started":"2023-07-24T09:25:40.492078Z"},"trusted":true},"outputs":[],"source":["MODEL_CLASSES = {\n","    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n","    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n","    'xlm': (XLMForSequenceClassification, XLMRobertaTokenizer, XLMConfig),\n","    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n","    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig)}\n","\n","model_type = 'albert'  # --> CHANGE WHAT MODEL YOU WANT HERE!!! <--###\n","# model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]\n","config_class = 'AlbertConfig'\n","model_class = 'TFAlbertForSequenceClassification'\n","tokenizer_class = 'AlbertTokenizer'\n","model_name = 'albert-base-v2' \n","tokenizer = AlbertTokenizer.from_pretrained(model_name, from_tf=True)\n"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2023-07-24T09:25:46.976020Z","iopub.status.busy":"2023-07-24T09:25:46.975640Z","iopub.status.idle":"2023-07-24T09:25:46.985216Z","shell.execute_reply":"2023-07-24T09:25:46.983928Z","shell.execute_reply.started":"2023-07-24T09:25:46.975988Z"},"trusted":true},"outputs":[],"source":["def input_id_maker(dataf, tokenizer):\n","    input_ids = []\n","    lengths = []\n","\n","    for i in range(len(dataf)):\n","        sen = dataf['text'].iloc[i]\n","        sen = tokenizer.tokenize(sen)\n","        # sen = tokenizer.tokenize(sen, add_prefix_space=True)\n","        CLS = tokenizer.cls_token\n","        SEP = tokenizer.sep_token\n","        if (len(sen) > 510):\n","            sen = sen[len(sen)-510:]\n","\n","        sen = [CLS] + sen + [SEP]\n","        encoded_sent = tokenizer.convert_tokens_to_ids(sen)\n","        input_ids.append(encoded_sent)\n","        lengths.append(len(encoded_sent))\n","\n","    input_ids = pad_sequences(\n","        input_ids, maxlen=512, value=0, dtype=\"long\", truncating=\"pre\", padding=\"post\")\n","    return input_ids, lengths\n"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2023-07-24T09:25:46.987487Z","iopub.status.busy":"2023-07-24T09:25:46.987089Z","iopub.status.idle":"2023-07-24T09:42:32.923585Z","shell.execute_reply":"2023-07-24T09:42:32.922287Z","shell.execute_reply.started":"2023-07-24T09:25:46.987455Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n","Keyword arguments {'add_prefix_space': True} not recognized.\n"]}],"source":["import time\n","start_time = time.time()\n","train_input_ids, train_lengths = input_id_maker(train_set, tokenizer)\n","validation_input_ids, validation_lengths = input_id_maker(validation_set, tokenizer)\n","test_input_ids, test_lengths = input_id_maker(test_set, tokenizer)\n","print(\"--- %s seconds ---\" % (time.time() - start_time))\n"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2023-07-24T09:42:32.925582Z","iopub.status.busy":"2023-07-24T09:42:32.925195Z","iopub.status.idle":"2023-07-24T09:42:32.931920Z","shell.execute_reply":"2023-07-24T09:42:32.930757Z","shell.execute_reply.started":"2023-07-24T09:42:32.925550Z"},"trusted":true},"outputs":[],"source":["def att_masking(input_ids):\n","    attention_masks = []\n","    for sent in input_ids:\n","        att_mask = [int(token_id > 0) for token_id in sent]\n","        attention_masks.append(att_mask)\n","    return attention_masks\n"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2023-07-24T09:42:32.934037Z","iopub.status.busy":"2023-07-24T09:42:32.933664Z","iopub.status.idle":"2023-07-24T09:42:46.414810Z","shell.execute_reply":"2023-07-24T09:42:46.413434Z","shell.execute_reply.started":"2023-07-24T09:42:32.934005Z"},"trusted":true},"outputs":[],"source":["train_attention_masks = att_masking(train_input_ids)\n","validation_attention_masks = att_masking(validation_input_ids)\n","\n","train_labels = train_set['label'].to_numpy().astype('int')\n","validation_labels = validation_set['label'].to_numpy().astype('int')\n","\n","test_attention_masks = att_masking(test_input_ids)\n","test_labels = test_set['label'].to_numpy().astype('int')\n"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["folder = f\"{model_type}/{model_name}\"\n","\n","if not os.path.exists(folder):\n","        os.makedirs(folder)\n"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2023-07-24T09:42:46.416994Z","iopub.status.busy":"2023-07-24T09:42:46.416631Z","iopub.status.idle":"2023-07-24T09:42:49.325365Z","shell.execute_reply":"2023-07-24T09:42:49.324038Z","shell.execute_reply.started":"2023-07-24T09:42:46.416963Z"},"trusted":true},"outputs":[],"source":["np.save(f'{folder}/train_input_ids.npy', train_input_ids)\n","np.save(f'{folder}/train_attention_masks.npy', train_attention_masks)\n","np.save(f'{folder}/train_labels.npy', train_labels)\n","\n","np.save(f'{folder}/validation_input_ids.npy', validation_input_ids)\n","np.save(f'{folder}/validation_attention_masks.npy', validation_attention_masks)\n","np.save(f'{folder}/validation_labels.npy', validation_labels)\n","\n","np.save(f'{folder}/test_input_ids.npy', test_input_ids)\n","np.save(f'{folder}/test_attention_masks.npy', test_attention_masks)\n","np.save(f'{folder}/test_labels.npy', test_labels)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"}},"nbformat":4,"nbformat_minor":4}
