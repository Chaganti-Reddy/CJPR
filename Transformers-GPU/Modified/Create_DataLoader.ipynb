{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jq4hFi35ZmM6"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "import textwrap\n",
    "import progressbar\n",
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "import time\n",
    "import datetime\n",
    "import json\n",
    "from sklearn.metrics import (accuracy_score, f1_score, recall_score, precision_score, confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zj1lTqgxy2hw"
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "df = pd.read_csv('ILDC.csv') \n",
    "train_set = df.query(\" split=='train' \")\n",
    "test_set = df.query(\" split=='test' \")\n",
    "validation_set = df.query(\" split=='dev' \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "Bl2FuqCdzK3U",
    "outputId": "d407a51d-5ab8-463d-c92d-04f45e1080f8"
   },
   "outputs": [],
   "source": [
    "# load all models and select roberta\n",
    "from transformers import PreTrainedModel, PreTrainedTokenizer, PretrainedConfig\n",
    "from transformers import BertForSequenceClassification, BertTokenizer, BertConfig\n",
    "from transformers import RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig\n",
    "from transformers import XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig\n",
    "from transformers import XLMForSequenceClassification, XLMRobertaTokenizer, XLMConfig\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig\n",
    "from transformers import GPT2ForSequenceClassification, GPT2Tokenizer, GPT2Config\n",
    "\n",
    "MODEL_CLASSES = {\n",
    "    'bert': (BertForSequenceClassification, BertTokenizer, BertConfig),\n",
    "    'xlnet': (XLNetForSequenceClassification, XLNetTokenizer, XLNetConfig),\n",
    "    'xlm': (XLMForSequenceClassification, XLMRobertaTokenizer, XLMConfig),\n",
    "    'roberta': (RobertaForSequenceClassification, RobertaTokenizer, RobertaConfig),\n",
    "    'distilbert': (DistilBertForSequenceClassification, DistilBertTokenizer, DistilBertConfig),\n",
    "    'gpt2': (GPT2ForSequenceClassification, GPT2Tokenizer, GPT2Config)}\n",
    "\n",
    "model_type = 'gpt2' ###--> CHANGE WHAT MODEL YOU WANT HERE!!! <--###\n",
    "model_class, tokenizer_class, config_class = MODEL_CLASSES[model_type]\n",
    "model_name = 'distilgpt2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZopB-jh_zK0l"
   },
   "outputs": [],
   "source": [
    "tokenizer = tokenizer_class.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rRzM1fMRzKxV"
   },
   "outputs": [],
   "source": [
    "def input_id_maker(dataf, tokenizer):\n",
    "  input_ids = []\n",
    "  lengths = []\n",
    "\n",
    "  for i in progressbar.progressbar(range(len(dataf['text']))):\n",
    "    sen = dataf['text'].iloc[i]\n",
    "    sen = tokenizer.tokenize(sen, add_prefix_space=True)\n",
    "    CLS = tokenizer.cls_token\n",
    "    SEP = tokenizer.sep_token\n",
    "    if(len(sen) > 510):\n",
    "      sen = sen[len(sen)-510:]\n",
    "\n",
    "    sen = [CLS] + sen + [SEP]\n",
    "    encoded_sent = tokenizer.convert_tokens_to_ids(sen)\n",
    "    input_ids.append(encoded_sent)\n",
    "    lengths.append(len(encoded_sent))\n",
    "\n",
    "  input_ids = pad_sequences(input_ids, maxlen=512, value=0, dtype=\"long\", truncating=\"pre\", padding=\"post\")\n",
    "  return input_ids, lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8_wm_voAzRQ_"
   },
   "outputs": [],
   "source": [
    "train_input_ids, train_lengths = input_id_maker(train_set, tokenizer)\n",
    "validation_input_ids, validation_lengths = input_id_maker(validation_set, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def att_masking(input_ids):\n",
    "    attention_masks = []\n",
    "    for sent in input_ids:\n",
    "        att_mask = [int(token_id > 0) for token_id in sent]\n",
    "        attention_masks.append(att_mask)\n",
    "    return attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_attention_masks = att_masking(train_input_ids)\n",
    "validation_attention_masks = att_masking(validation_input_ids)\n",
    "\n",
    "train_labels = train_set['label'].to_numpy().astype('int')\n",
    "validation_labels = validation_set['label'].to_numpy().astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "j9Ic3b3GzRNh"
   },
   "outputs": [],
   "source": [
    "train_inputs = train_input_ids\n",
    "validation_inputs = validation_input_ids\n",
    "train_masks = train_attention_masks\n",
    "validation_masks = validation_attention_masks\n",
    "\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "train_labels = torch.tensor(train_labels)\n",
    "train_masks = torch.tensor(train_masks)\n",
    "\n",
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "validation_labels = torch.tensor(validation_labels)\n",
    "validation_masks = torch.tensor(validation_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lpn2rYJ5zRKz"
   },
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size = batch_size)\n",
    "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
    "validation_sampler = RandomSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GH-QlBK6zRH2"
   },
   "outputs": [],
   "source": [
    "torch.save(train_dataloader, f\"train_{model_name}_dataloader_batch_size_{batch_size}.pt\")\n",
    "torch.save(validation_dataloader, f\"validation_{model_name}_dataloader_batch_size_{batch_size}.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
